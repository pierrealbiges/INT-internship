{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017-05-02 : grabbing the framerate and plotting it\n",
    "----------------------------\n",
    "\n",
    "- [x] Capturing a framerate for each downscale parameter possible\n",
    "\n",
    "Obtaining different framerates will allow us to chose which downscale using for an optimum recording.  \n",
    "The framerate seems to be hightly dependent of the program simplicity. Going from : \n",
    "\n",
    "    (...)\n",
    "    for i in range(0,num_frames):\n",
    "        Ph.grab()\n",
    "        frame = Ph.grab()\n",
    "        (...)\n",
    "        \n",
    "to :\n",
    "\n",
    "    (...)\n",
    "    for i in range(0,num_frames):\n",
    "        frame = Ph.grab()\n",
    "        (...)\n",
    "        \n",
    "Seem to double the framerate recorded (from 7 to 13 FPS). It is understandable since the first version executed Ph.grab() two times per loop. Also, the version b (limit : time recorded) seems to be a bit faster than the version a (limit : number of frames recorded) as it record at 14-15 FPS (vs 13 FPS).  \n",
    "The program contained a little writing error that prevented it to work correctly when the downscale parameter was superior to 1. Going from :\n",
    "\n",
    "    (...)\n",
    "    if DOWNSCALE > 1 :\n",
    "        W = self.cap.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH)\n",
    "        H = self.cap.set(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT)\n",
    "        (...)\n",
    "\n",
    "to :\n",
    "\n",
    "    (...)\n",
    "    if DOWNSCALE > 1 :\n",
    "        W = self.cap.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH)\n",
    "        H = self.cap.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT)\n",
    "        (...)    \n",
    "\n",
    "I built a loop that allow to modify the downscale parameter :\n",
    "\n",
    "    (...)\n",
    "    for ds in range(10):\n",
    "        Ph = PhotoReceptor(w=1280, h=720, DOWNSCALE = ds)\n",
    "        (...)\n",
    "\n",
    "In these conditions, the framerate seems to not be influenced by the downscale, as the program output the same FPS for each of them (except for downscale = 2).\n",
    "\n",
    "    Before downscale. dim1 : 720, dim2 : 1280\n",
    "    Using OpenCV\n",
    "    After downscale 1. dim1 : 720.0, dim2 : 1280.0\n",
    "    Frame rate : 15.0 \n",
    "\n",
    "    Before downscale. dim1 : 720, dim2 : 1280\n",
    "    Using OpenCV\n",
    "    After downscale 2. dim1 : 288.0, dim2 : 352.0\n",
    "    Frame rate : 17.0 \n",
    "\n",
    "    Before downscale. dim1 : 720, dim2 : 1280\n",
    "    Using OpenCV\n",
    "    After downscale 3. dim1 : 240.0, dim2 : 320.0\n",
    "    Frame rate : 15.0 \n",
    "\n",
    "    Before downscale. dim1 : 720, dim2 : 1280\n",
    "    Using OpenCV\n",
    "    After downscale 4. dim1 : 144.0, dim2 : 176.0\n",
    "    Frame rate : 15.0\n",
    "    \n",
    "    (...)\n",
    "    \n",
    "In addition, a problem appear from downscale = 7 to beyond : the new dimensions are not reduced as expected. It looks like the program is not able to reduce them this much and so it may represent the upper limit of the downscaling in these conditions.  \n",
    "\n",
    "    (...)\n",
    "    \n",
    "    Before downscale. dim1 : 720, dim2 : 1280\n",
    "    Using OpenCV\n",
    "    After downscale 5. dim1 : 144.0, dim2 : 176.0\n",
    "    Frame rate : 15.0 \n",
    "\n",
    "    Before downscale. dim1 : 720, dim2 : 1280\n",
    "    Using OpenCV\n",
    "    After downscale 6. dim1 : 120.0, dim2 : 160.0\n",
    "    Frame rate : 15.0 \n",
    "\n",
    "    Before downscale. dim1 : 720, dim2 : 1280\n",
    "    Using OpenCV\n",
    "    After downscale 7. dim1 : 480.0, dim2 : 640.0\n",
    "    Frame rate : 15.0 \n",
    "\n",
    "    Before downscale. dim1 : 720, dim2 : 1280\n",
    "    Using OpenCV\n",
    "    After downscale 8. dim1 : 480.0, dim2 : 640.0\n",
    "    Frame rate : 15.0 \n",
    "    \n",
    "    (...)\n",
    "    \n",
    "More informations about plotting with matplotlib : https://matplotlib.org/users/pyplot_tutorial.html   \n",
    "More informations about plot() : https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot\n",
    "\n",
    "-  [x] Building a plot comparing the framerate with the downscale parameter\n",
    "\n",
    "The plot construction is simple. It introduce two lists that get completed during the program execution :\n",
    "\n",
    "    (...)\n",
    "    downscales = []\n",
    "    frames = []\n",
    "    (...)\n",
    "        frames.append(fps)\n",
    "        downscales.append(ds)\n",
    "        (...)\n",
    "        \n",
    "That get called by a few lines :\n",
    "\n",
    "    plt.plot(downscales, frames)\n",
    "    plt.title('Effect of downscale on framerate')\n",
    "    plt.xlabel('Downscale')\n",
    "    plt.ylabel('FPS')\n",
    "    plt.show()\n",
    "\n",
    "The program correctly shows the plot but it doesn't give any useful information, because the framerate doesn't seems influenced by the downscale.  \n",
    "I tried to obtain more detailed informations, so I modified a few lines. Going from : \n",
    "\n",
    "    (...)\n",
    "    for ds in range(1,7):\n",
    "        (...)\n",
    "        fps = nb_frames // seconds\n",
    "        (...)\n",
    "        \n",
    "to :\n",
    "\n",
    "    (...)\n",
    "    for ds in np.arrange(1,7,0.5): #Modification needed because range() doesn't use floats, but np.arange() do\n",
    "        (...)\n",
    "        fps = nb_frames / seconds\n",
    "        (...)\n",
    "        \n",
    "After some tries, it seems that the framerate is hightly test variable but it almost not influenced by the downscale.\n",
    "        \n",
    "I need to check with L. Perrinet if everything in the program is alright before going on the next steps.  \n",
    "\n",
    "# 2017-05-03 : beggining the distant communication program\n",
    "------------------------\n",
    "\n",
    "I modified the program to integrate the framerate grabbing into the grab() function :\n",
    "\n",
    "    def grab(self, nb_frames) :\n",
    "            self.start = time.time()\n",
    "\n",
    "            for nb in range(nb_frames):\n",
    "                ret, frame_bgr = self.cap.read()\n",
    "                #frame = frame_bgr[:, :, ::-1] #BGR to RBG.\n",
    "                frame = frame_bgr\n",
    "\n",
    "                self.end = time.time()\n",
    "                self.seconds = self.end - self.start\n",
    "\n",
    "                fps = nb_frames / self.seconds\n",
    "                print ('Framerate :', fps,'\\n')\n",
    "\n",
    "                return frame, fps\n",
    "                \n",
    "That allowed me to make the calling block simplier :\n",
    "\n",
    "    nb_frames = 50\n",
    "    downscales_a, frames_a = [], []\n",
    "    for ds in np.arange(1,7,0.5):\n",
    "\n",
    "        Ph = PhotoReceptor(w=1280, h=720, DOWNSCALE = ds)\n",
    "\n",
    "        frame, fps = Ph.grab(nb_frames)\n",
    "\n",
    "        Ph.close()\n",
    "\n",
    "        frames_a.append(fps)\n",
    "        downscales_a.append(ds)\n",
    "    \n",
    "But the difference seems to have unbelievably speed up the framerate, going from about 16 FPS to more than 70 FPS. There must be an error in the framerate computation. Returning to the last checkpoint.\n",
    "\n",
    "- [ ] Etablishing a communication between the program and a distant camera\n",
    "\n",
    "The communication must contain 3 things :  \n",
    "1) A way to ask the camera if it's ready to record  \n",
    "2) A way for the camera to respond positively or negatively  \n",
    "3) A way to cut down the communication  \n",
    "\n",
    "The communication can be etablished through a program that'll look like this pseudocode :\n",
    "\n",
    "    __init__\n",
    "    while True:\n",
    "        grab()\n",
    "        code\n",
    "        send/recieve\n",
    "    close()\n",
    "    \n",
    "More informations about the picamera library, allowing to communicate with a camera connected to a Raspberry Pi : https://github.com/laurentperrinet/openRetina/blob/master/src/openRetina.py  \n",
    "Complete documentation : http://picamera.readthedocs.io/en/release-1.13/  \n",
    "Note that may be important if recording a video or using a long exposure time : the picamera use a rolling shutter (vs global shutter, more informations : https://en.wikipedia.org/wiki/Rolling_shutter)  \n",
    "A lot of informations about the current objective is available here : http://picamera.readthedocs.io/en/release-1.13/recipes1.html#capturing-to-a-network-stream  \n",
    "\n",
    "The program must be divided in two scripts : one on the RaspBerry Pi that'll be used as a client, the other on a computer that'll be used as a server.  \n",
    "The client will first send a 32-bit integer containing the length of the image that'll follow. If this length is 0, this indicate that no more images will be sent and the connection is shuted down.\n",
    "\n",
    "    (...)\n",
    "    connection = server_socket.accept()[0].makefile('rb')\n",
    "    (...)\n",
    "    \n",
    "A problem seem to be provoked by the previous codeline. The program seem unable to go beyond it.  \n",
    "More informations about the socket library : https://docs.python.org/2/library/socket.html  \n",
    "After dividing the line into two :\n",
    "\n",
    "    (...)\n",
    "    connection = server_socket.accept()[0]\n",
    "    connection.makefile('rb')\n",
    "    (...)\n",
    "\n",
    "It seems that the problem come from the first line, as a keyboard interrupt output the following error :\n",
    "\n",
    "    (...)\n",
    "    ---> 23 connection = server_socket.accept()\n",
    "    (...)\n",
    "    /usr/lib/python2.7/socket.pyc in accept(self)\n",
    "        204 \n",
    "        205     def accept(self):\n",
    "    --> 206         sock, addr = self._sock.accept()\n",
    "    (...)\n",
    "    \n",
    "The problem may come from the fact that no connection is etablished, because the client script is not writen et/or executed at this point.  \n",
    "More informations about the struct library : https://docs.python.org/2/library/struct.html\n",
    "More informations about the IO library : https://docs.python.org/2/library/io.html\n",
    "\n",
    "# 2017-05-04\n",
    "----------------\n",
    "\n",
    "Trying to solve some problems :\n",
    "\n",
    "The graphics shows that there is no frame rate difference when applying a resolution downscale. This may come from a problem when defining the new camera resolution. Some of the downscales may not work because the resolutions we try to apply aren't supported by the camera/its driver.  \n",
    "I'm looking for the most common resolutions to apply it to the program, instead of semi-randomly founding them with a np.arange() function.\n",
    "\n",
    "- [ ] Finding the right camera resolutions to apply as downscales\n",
    "\n",
    "A list of the most common ones is available here : https://en.wikipedia.org/wiki/List_of_common_resolutions  \n",
    "The 1280×720 native resolution of the camera display a pixel number equivalent to listed on the previous link. \n",
    "The camera support lot of resolutions (w x h, downscale in comparison of the native resolution), as : \n",
    "- 1280x720 (native)\n",
    "- 1024x576 (downscale = 1.25)\n",
    "- 720x480 (downscale = 1.5)\n",
    "- 640x480 (downscale = ? and >=6.5)\n",
    "- 352x288 (downscale = 2)\n",
    "- 320x240 (downscale = 3)\n",
    "- 176x144 (downscale = 4)\n",
    "- 160x120 (downscale = 6)\n",
    "\n",
    "I don't find the exact downscale parameter to apply a 720x480 resolution, as it seems to goes directly from 1024x576 to 352x288, even with a step = 0.2.\n",
    "\n",
    "- [x] Search more informations about the cv.SetCaptureProperty(capture, property_id, value) function\n",
    "\n",
    "Some informations available here : http://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-set\n",
    "The following functions : \n",
    "\n",
    "    self.cap.set(cv2.cv.CV_CAP_PROP_FRAME_WIDTH, int(W/self.DOWNSCALE))\n",
    "    self.cap.set(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT, int(H/self.DOWNSCALE))\n",
    "    \n",
    "Could have only modified the screen size displayed and not the recording proprieties, so this function :\n",
    "\n",
    "    cv.SetCaptureProperty(capture, property_id, value)\n",
    "    \n",
    "Found on the OpenCv documentation could have been interesting. But it seems that it's outdated and only supporting video files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
